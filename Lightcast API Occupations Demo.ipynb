{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo is based on Rogers' pull [here.](https://analyst.lightcast.io/analyst/?t=4b8JV)\n",
    "\n",
    "All occupations at a 5 digit level. All years.\n",
    "MSA 19100 for Dallas-Fort Worth-Arlington, TX.\n",
    "\n",
    "Columns:\n",
    "- Jobs\n",
    "- Openings\n",
    "- Replacements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import this library and instantiate an instance of the Lightcast API (replace user and pass with your credentials).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyghtcast.lightcast import Lightcast\n",
    "lc = Lightcast(user, pass)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lightcast API expects a POST request of a JSON that contains \"metrics\" and \"constraints\". Metrics are just the column names. Constraints are how the data is to be filtered. The lightcast library helps us abstract by creating the JSON and POSTing it for us. All we need to do is define a list of columns we want, and a list of constraints.\n",
    "\n",
    "Let's start with the columns. I want my query to return the values for the columns listed at the beginning of this document, for all of the years available in lightcast (2001 - 2034).\n",
    "\n",
    "The data as it's organized in the API separates each year into it's own column for each data point, formatted like \"Column.Year\". For example, if I wanted to get \"Jobs\" in 2001, the column name is \"Jobs.2001\".\n",
    "\n",
    "Let's assemble our list of columns to request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jobs.2001',\n",
       " 'Openings.2001',\n",
       " 'Replacements.2001',\n",
       " 'Jobs.2002',\n",
       " 'Openings.2002',\n",
       " 'Replacements.2002',\n",
       " 'Jobs.2003',\n",
       " 'Openings.2003',\n",
       " 'Replacements.2003',\n",
       " 'Jobs.2004',\n",
       " 'Openings.2004',\n",
       " 'Replacements.2004',\n",
       " 'Jobs.2005',\n",
       " 'Openings.2005',\n",
       " 'Replacements.2005',\n",
       " 'Jobs.2006',\n",
       " 'Openings.2006',\n",
       " 'Replacements.2006',\n",
       " 'Jobs.2007',\n",
       " 'Openings.2007',\n",
       " 'Replacements.2007',\n",
       " 'Jobs.2008',\n",
       " 'Openings.2008',\n",
       " 'Replacements.2008',\n",
       " 'Jobs.2009',\n",
       " 'Openings.2009',\n",
       " 'Replacements.2009',\n",
       " 'Jobs.2010',\n",
       " 'Openings.2010',\n",
       " 'Replacements.2010',\n",
       " 'Jobs.2011',\n",
       " 'Openings.2011',\n",
       " 'Replacements.2011',\n",
       " 'Jobs.2012',\n",
       " 'Openings.2012',\n",
       " 'Replacements.2012',\n",
       " 'Jobs.2013',\n",
       " 'Openings.2013',\n",
       " 'Replacements.2013',\n",
       " 'Jobs.2014',\n",
       " 'Openings.2014',\n",
       " 'Replacements.2014',\n",
       " 'Jobs.2015',\n",
       " 'Openings.2015',\n",
       " 'Replacements.2015',\n",
       " 'Jobs.2016',\n",
       " 'Openings.2016',\n",
       " 'Replacements.2016',\n",
       " 'Jobs.2017',\n",
       " 'Openings.2017',\n",
       " 'Replacements.2017',\n",
       " 'Jobs.2018',\n",
       " 'Openings.2018',\n",
       " 'Replacements.2018',\n",
       " 'Jobs.2019',\n",
       " 'Openings.2019',\n",
       " 'Replacements.2019',\n",
       " 'Jobs.2020',\n",
       " 'Openings.2020',\n",
       " 'Replacements.2020',\n",
       " 'Jobs.2021',\n",
       " 'Openings.2021',\n",
       " 'Replacements.2021',\n",
       " 'Jobs.2022',\n",
       " 'Openings.2022',\n",
       " 'Replacements.2022',\n",
       " 'Jobs.2023',\n",
       " 'Openings.2023',\n",
       " 'Replacements.2023',\n",
       " 'Jobs.2024',\n",
       " 'Openings.2024',\n",
       " 'Replacements.2024',\n",
       " 'Jobs.2025',\n",
       " 'Openings.2025',\n",
       " 'Replacements.2025',\n",
       " 'Jobs.2026',\n",
       " 'Openings.2026',\n",
       " 'Replacements.2026',\n",
       " 'Jobs.2027',\n",
       " 'Openings.2027',\n",
       " 'Replacements.2027',\n",
       " 'Jobs.2028',\n",
       " 'Openings.2028',\n",
       " 'Replacements.2028',\n",
       " 'Jobs.2029',\n",
       " 'Openings.2029',\n",
       " 'Replacements.2029',\n",
       " 'Jobs.2030',\n",
       " 'Openings.2030',\n",
       " 'Replacements.2030',\n",
       " 'Jobs.2031',\n",
       " 'Openings.2031',\n",
       " 'Replacements.2031',\n",
       " 'Jobs.2032',\n",
       " 'Openings.2032',\n",
       " 'Replacements.2032',\n",
       " 'Jobs.2033',\n",
       " 'Openings.2033',\n",
       " 'Replacements.2033']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_year = 2001\n",
    "end_year = 2034\n",
    "\n",
    "col_names = [\n",
    "    \"Jobs\",\n",
    "    \"Openings\",\n",
    "    \"Replacements\",\n",
    "]\n",
    "\n",
    "cols = []\n",
    "\n",
    "# To make this easier instead of typing out every year, I'll just use a loop to append the years.\n",
    "for year in range(start_year, end_year ):\n",
    "    for col in col_names:\n",
    "        cols.append(f\"{col}.{year}\")\n",
    "\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraints are slightly more complicated. We need to construct a list where each item in the list is a dictionary that describes how the data should be filtered. Each dictonary requires a a `dimensionName` field, and either a `map` or `mapLevel` field.\n",
    "\n",
    "Dimensions are the various fields on which the API can be filtered, and can be discovered per dataset by hitting the data discovery API (TODO: elaborate on this in a separate doc).\n",
    "\n",
    "The `map` property defines what specific values are being filtered for. `mapLevel` is a shorthand for when there is a bunch of values we want to map. We'll see examples of each here.\n",
    "\n",
    "The [lightcast docs](https://docs.lightcast.dev/apis/core-lmi#data-queries) go more in depth on structuring queries.\n",
    "\n",
    "Let's create the constrants list and start by defining the constraint for the geography. In this case, we want to pull data in the Dallas-Fort Worth-Arlington area, so lets add the constraint for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = []\n",
    "\n",
    "constraints.append({\n",
    "    \"dimensionName\": \"Area\",\n",
    "    \"map\": {\n",
    "        \"Dallas-Fort Worth-Arlington, TX\": [\"MSA19100\"]\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Area\" dimension handles anything related to geographies. In this case we know which MSA we want to filter on, so we can just put tho MSA in. The key values for the map are arbitrary, I decided to make it \"Dallas-Fort Worth-Arlington, TX\" for readability.\n",
    "\n",
    "Now we want to pull occupations at a 5 digit level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints.append({\n",
    "    \"dimensionName\": \"Occupation\",\n",
    "    \"mapLevel\": {\"level\": 5, \"predicate\": [\"00-0000\"]}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension here is \"Occupation\", which allows us to filter on SOC codes. We use a mapLevel this time, because listing every single SOC code would be tedious and impractical. mapLevel lets us quickly define the spectrum of data we want.\n",
    "\n",
    "The predicate can be thought of as the \"parent\" for which we should pull all its children. \"00-0000\" is the code for all occupations we wanted to narrow it to, for example, Management Occupations, we could do \"11-0000\" instead.\n",
    "\n",
    "Now that we have our constraints, we can build our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': [{'name': 'Jobs.2001'},\n",
       "  {'name': 'Openings.2001'},\n",
       "  {'name': 'Replacements.2001'},\n",
       "  {'name': 'Jobs.2002'},\n",
       "  {'name': 'Openings.2002'},\n",
       "  {'name': 'Replacements.2002'},\n",
       "  {'name': 'Jobs.2003'},\n",
       "  {'name': 'Openings.2003'},\n",
       "  {'name': 'Replacements.2003'},\n",
       "  {'name': 'Jobs.2004'},\n",
       "  {'name': 'Openings.2004'},\n",
       "  {'name': 'Replacements.2004'},\n",
       "  {'name': 'Jobs.2005'},\n",
       "  {'name': 'Openings.2005'},\n",
       "  {'name': 'Replacements.2005'},\n",
       "  {'name': 'Jobs.2006'},\n",
       "  {'name': 'Openings.2006'},\n",
       "  {'name': 'Replacements.2006'},\n",
       "  {'name': 'Jobs.2007'},\n",
       "  {'name': 'Openings.2007'},\n",
       "  {'name': 'Replacements.2007'},\n",
       "  {'name': 'Jobs.2008'},\n",
       "  {'name': 'Openings.2008'},\n",
       "  {'name': 'Replacements.2008'},\n",
       "  {'name': 'Jobs.2009'},\n",
       "  {'name': 'Openings.2009'},\n",
       "  {'name': 'Replacements.2009'},\n",
       "  {'name': 'Jobs.2010'},\n",
       "  {'name': 'Openings.2010'},\n",
       "  {'name': 'Replacements.2010'},\n",
       "  {'name': 'Jobs.2011'},\n",
       "  {'name': 'Openings.2011'},\n",
       "  {'name': 'Replacements.2011'},\n",
       "  {'name': 'Jobs.2012'},\n",
       "  {'name': 'Openings.2012'},\n",
       "  {'name': 'Replacements.2012'},\n",
       "  {'name': 'Jobs.2013'},\n",
       "  {'name': 'Openings.2013'},\n",
       "  {'name': 'Replacements.2013'},\n",
       "  {'name': 'Jobs.2014'},\n",
       "  {'name': 'Openings.2014'},\n",
       "  {'name': 'Replacements.2014'},\n",
       "  {'name': 'Jobs.2015'},\n",
       "  {'name': 'Openings.2015'},\n",
       "  {'name': 'Replacements.2015'},\n",
       "  {'name': 'Jobs.2016'},\n",
       "  {'name': 'Openings.2016'},\n",
       "  {'name': 'Replacements.2016'},\n",
       "  {'name': 'Jobs.2017'},\n",
       "  {'name': 'Openings.2017'},\n",
       "  {'name': 'Replacements.2017'},\n",
       "  {'name': 'Jobs.2018'},\n",
       "  {'name': 'Openings.2018'},\n",
       "  {'name': 'Replacements.2018'},\n",
       "  {'name': 'Jobs.2019'},\n",
       "  {'name': 'Openings.2019'},\n",
       "  {'name': 'Replacements.2019'},\n",
       "  {'name': 'Jobs.2020'},\n",
       "  {'name': 'Openings.2020'},\n",
       "  {'name': 'Replacements.2020'},\n",
       "  {'name': 'Jobs.2021'},\n",
       "  {'name': 'Openings.2021'},\n",
       "  {'name': 'Replacements.2021'},\n",
       "  {'name': 'Jobs.2022'},\n",
       "  {'name': 'Openings.2022'},\n",
       "  {'name': 'Replacements.2022'},\n",
       "  {'name': 'Jobs.2023'},\n",
       "  {'name': 'Openings.2023'},\n",
       "  {'name': 'Replacements.2023'},\n",
       "  {'name': 'Jobs.2024'},\n",
       "  {'name': 'Openings.2024'},\n",
       "  {'name': 'Replacements.2024'},\n",
       "  {'name': 'Jobs.2025'},\n",
       "  {'name': 'Openings.2025'},\n",
       "  {'name': 'Replacements.2025'},\n",
       "  {'name': 'Jobs.2026'},\n",
       "  {'name': 'Openings.2026'},\n",
       "  {'name': 'Replacements.2026'},\n",
       "  {'name': 'Jobs.2027'},\n",
       "  {'name': 'Openings.2027'},\n",
       "  {'name': 'Replacements.2027'},\n",
       "  {'name': 'Jobs.2028'},\n",
       "  {'name': 'Openings.2028'},\n",
       "  {'name': 'Replacements.2028'},\n",
       "  {'name': 'Jobs.2029'},\n",
       "  {'name': 'Openings.2029'},\n",
       "  {'name': 'Replacements.2029'},\n",
       "  {'name': 'Jobs.2030'},\n",
       "  {'name': 'Openings.2030'},\n",
       "  {'name': 'Replacements.2030'},\n",
       "  {'name': 'Jobs.2031'},\n",
       "  {'name': 'Openings.2031'},\n",
       "  {'name': 'Replacements.2031'},\n",
       "  {'name': 'Jobs.2032'},\n",
       "  {'name': 'Openings.2032'},\n",
       "  {'name': 'Replacements.2032'},\n",
       "  {'name': 'Jobs.2033'},\n",
       "  {'name': 'Openings.2033'},\n",
       "  {'name': 'Replacements.2033'}],\n",
       " 'constraints': [{'dimensionName': 'Area',\n",
       "   'map': {'Dallas-Fort Worth-Arlington, TX': ['MSA19100']}},\n",
       "  {'dimensionName': 'Occupation',\n",
       "   'mapLevel': {'level': 5, 'predicate': ['00-0000']}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = lightcast.build_query_corelmi(cols, constraints)\n",
    "\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `build_query_corelmi` function constructs the JSON to be POSTed to the API. I demonstrated the output of that just to show how the sausage is made, but you won't have to interact with the JSON or API directry, it's all abstracted in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Jobs.2001</th>\n",
       "      <th>Openings.2001</th>\n",
       "      <th>Replacements.2001</th>\n",
       "      <th>Jobs.2002</th>\n",
       "      <th>Openings.2002</th>\n",
       "      <th>Replacements.2002</th>\n",
       "      <th>Jobs.2003</th>\n",
       "      <th>Openings.2003</th>\n",
       "      <th>...</th>\n",
       "      <th>Replacements.2030</th>\n",
       "      <th>Jobs.2031</th>\n",
       "      <th>Openings.2031</th>\n",
       "      <th>Replacements.2031</th>\n",
       "      <th>Jobs.2032</th>\n",
       "      <th>Openings.2032</th>\n",
       "      <th>Replacements.2032</th>\n",
       "      <th>Jobs.2033</th>\n",
       "      <th>Openings.2033</th>\n",
       "      <th>Replacements.2033</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>9018.095654</td>\n",
       "      <td>698.348972</td>\n",
       "      <td>595.194313</td>\n",
       "      <td>8843.357700</td>\n",
       "      <td>1038.829689</td>\n",
       "      <td>583.661608</td>\n",
       "      <td>9046.858183</td>\n",
       "      <td>838.099657</td>\n",
       "      <td>...</td>\n",
       "      <td>1893.000897</td>\n",
       "      <td>29336.228198</td>\n",
       "      <td>2544.536055</td>\n",
       "      <td>1936.191061</td>\n",
       "      <td>29944.563259</td>\n",
       "      <td>2540.088389</td>\n",
       "      <td>1976.341175</td>\n",
       "      <td>30508.302598</td>\n",
       "      <td>2539.545775</td>\n",
       "      <td>2013.547971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>11-1021</td>\n",
       "      <td>47028.435452</td>\n",
       "      <td>4122.239825</td>\n",
       "      <td>3715.246401</td>\n",
       "      <td>46561.402255</td>\n",
       "      <td>4517.956374</td>\n",
       "      <td>3678.350778</td>\n",
       "      <td>47265.726935</td>\n",
       "      <td>5021.502312</td>\n",
       "      <td>...</td>\n",
       "      <td>12054.862846</td>\n",
       "      <td>154152.343390</td>\n",
       "      <td>13581.069350</td>\n",
       "      <td>12178.035128</td>\n",
       "      <td>155555.327419</td>\n",
       "      <td>13522.607729</td>\n",
       "      <td>12288.870866</td>\n",
       "      <td>156788.715094</td>\n",
       "      <td>13479.537930</td>\n",
       "      <td>12386.308492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>11-1031</td>\n",
       "      <td>251.406783</td>\n",
       "      <td>26.238433</td>\n",
       "      <td>18.101288</td>\n",
       "      <td>254.319931</td>\n",
       "      <td>19.669527</td>\n",
       "      <td>18.311035</td>\n",
       "      <td>250.547165</td>\n",
       "      <td>20.575083</td>\n",
       "      <td>...</td>\n",
       "      <td>30.056246</td>\n",
       "      <td>424.330956</td>\n",
       "      <td>37.153531</td>\n",
       "      <td>30.551829</td>\n",
       "      <td>430.927037</td>\n",
       "      <td>37.367727</td>\n",
       "      <td>31.026747</td>\n",
       "      <td>437.263244</td>\n",
       "      <td>37.581246</td>\n",
       "      <td>31.482954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>11-2011</td>\n",
       "      <td>1148.206144</td>\n",
       "      <td>152.418890</td>\n",
       "      <td>99.893935</td>\n",
       "      <td>1142.861484</td>\n",
       "      <td>205.525289</td>\n",
       "      <td>99.428949</td>\n",
       "      <td>1191.273163</td>\n",
       "      <td>109.273548</td>\n",
       "      <td>...</td>\n",
       "      <td>153.029482</td>\n",
       "      <td>1777.853832</td>\n",
       "      <td>172.302763</td>\n",
       "      <td>154.673283</td>\n",
       "      <td>1795.368940</td>\n",
       "      <td>172.293758</td>\n",
       "      <td>156.197098</td>\n",
       "      <td>1811.367608</td>\n",
       "      <td>171.647811</td>\n",
       "      <td>157.588982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>11-2021</td>\n",
       "      <td>5128.313437</td>\n",
       "      <td>455.787249</td>\n",
       "      <td>400.008448</td>\n",
       "      <td>4998.532250</td>\n",
       "      <td>515.951814</td>\n",
       "      <td>389.885516</td>\n",
       "      <td>5029.295890</td>\n",
       "      <td>495.019726</td>\n",
       "      <td>...</td>\n",
       "      <td>1534.479268</td>\n",
       "      <td>20006.057576</td>\n",
       "      <td>1866.319212</td>\n",
       "      <td>1560.472491</td>\n",
       "      <td>20311.904296</td>\n",
       "      <td>1865.146091</td>\n",
       "      <td>1584.328535</td>\n",
       "      <td>20592.721852</td>\n",
       "      <td>1863.508498</td>\n",
       "      <td>1606.232304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>53-7081</td>\n",
       "      <td>1875.814624</td>\n",
       "      <td>337.130055</td>\n",
       "      <td>228.849384</td>\n",
       "      <td>1881.758679</td>\n",
       "      <td>270.131464</td>\n",
       "      <td>229.574559</td>\n",
       "      <td>1844.072183</td>\n",
       "      <td>280.490312</td>\n",
       "      <td>...</td>\n",
       "      <td>617.149569</td>\n",
       "      <td>5124.679643</td>\n",
       "      <td>683.938967</td>\n",
       "      <td>625.210916</td>\n",
       "      <td>5181.722582</td>\n",
       "      <td>681.522643</td>\n",
       "      <td>632.170155</td>\n",
       "      <td>5228.963573</td>\n",
       "      <td>680.855623</td>\n",
       "      <td>637.933556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>53-7121</td>\n",
       "      <td>584.304585</td>\n",
       "      <td>67.823406</td>\n",
       "      <td>67.779332</td>\n",
       "      <td>534.546580</td>\n",
       "      <td>69.126916</td>\n",
       "      <td>62.007403</td>\n",
       "      <td>497.238806</td>\n",
       "      <td>77.010336</td>\n",
       "      <td>...</td>\n",
       "      <td>11.550907</td>\n",
       "      <td>101.186765</td>\n",
       "      <td>14.122842</td>\n",
       "      <td>11.737665</td>\n",
       "      <td>103.571943</td>\n",
       "      <td>13.251697</td>\n",
       "      <td>12.014345</td>\n",
       "      <td>104.804102</td>\n",
       "      <td>13.011831</td>\n",
       "      <td>12.157276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>53-7199</td>\n",
       "      <td>478.365401</td>\n",
       "      <td>60.594228</td>\n",
       "      <td>55.490387</td>\n",
       "      <td>444.462927</td>\n",
       "      <td>56.328566</td>\n",
       "      <td>51.557700</td>\n",
       "      <td>408.282583</td>\n",
       "      <td>54.992191</td>\n",
       "      <td>...</td>\n",
       "      <td>88.291228</td>\n",
       "      <td>783.633158</td>\n",
       "      <td>112.199974</td>\n",
       "      <td>90.901446</td>\n",
       "      <td>804.931685</td>\n",
       "      <td>114.514874</td>\n",
       "      <td>93.372075</td>\n",
       "      <td>826.074484</td>\n",
       "      <td>114.891973</td>\n",
       "      <td>95.824640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>55-9999</td>\n",
       "      <td>7447.886306</td>\n",
       "      <td>1003.268391</td>\n",
       "      <td>811.819607</td>\n",
       "      <td>7626.540682</td>\n",
       "      <td>963.369243</td>\n",
       "      <td>831.292934</td>\n",
       "      <td>7758.161432</td>\n",
       "      <td>890.263296</td>\n",
       "      <td>...</td>\n",
       "      <td>1071.491864</td>\n",
       "      <td>9938.374974</td>\n",
       "      <td>1190.661953</td>\n",
       "      <td>1083.282872</td>\n",
       "      <td>10045.754055</td>\n",
       "      <td>1201.641758</td>\n",
       "      <td>1094.987192</td>\n",
       "      <td>10152.408621</td>\n",
       "      <td>1212.607178</td>\n",
       "      <td>1106.612540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>99-9999</td>\n",
       "      <td>5156.888819</td>\n",
       "      <td>2372.202081</td>\n",
       "      <td>562.100881</td>\n",
       "      <td>6966.990018</td>\n",
       "      <td>786.682558</td>\n",
       "      <td>759.401912</td>\n",
       "      <td>5061.183845</td>\n",
       "      <td>1156.905390</td>\n",
       "      <td>...</td>\n",
       "      <td>3886.322868</td>\n",
       "      <td>36241.442371</td>\n",
       "      <td>4478.711024</td>\n",
       "      <td>3950.317218</td>\n",
       "      <td>36769.836176</td>\n",
       "      <td>4483.520834</td>\n",
       "      <td>4007.912143</td>\n",
       "      <td>37245.444867</td>\n",
       "      <td>4487.857196</td>\n",
       "      <td>4059.753491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Area Occupation     Jobs.2001  Openings.2001  \\\n",
       "0    Dallas-Fort Worth-Arlington, TX    11-1011   9018.095654     698.348972   \n",
       "1    Dallas-Fort Worth-Arlington, TX    11-1021  47028.435452    4122.239825   \n",
       "2    Dallas-Fort Worth-Arlington, TX    11-1031    251.406783      26.238433   \n",
       "3    Dallas-Fort Worth-Arlington, TX    11-2011   1148.206144     152.418890   \n",
       "4    Dallas-Fort Worth-Arlington, TX    11-2021   5128.313437     455.787249   \n",
       "..                               ...        ...           ...            ...   \n",
       "793  Dallas-Fort Worth-Arlington, TX    53-7081   1875.814624     337.130055   \n",
       "794  Dallas-Fort Worth-Arlington, TX    53-7121    584.304585      67.823406   \n",
       "795  Dallas-Fort Worth-Arlington, TX    53-7199    478.365401      60.594228   \n",
       "796  Dallas-Fort Worth-Arlington, TX    55-9999   7447.886306    1003.268391   \n",
       "797  Dallas-Fort Worth-Arlington, TX    99-9999   5156.888819    2372.202081   \n",
       "\n",
       "     Replacements.2001     Jobs.2002  Openings.2002  Replacements.2002  \\\n",
       "0           595.194313   8843.357700    1038.829689         583.661608   \n",
       "1          3715.246401  46561.402255    4517.956374        3678.350778   \n",
       "2            18.101288    254.319931      19.669527          18.311035   \n",
       "3            99.893935   1142.861484     205.525289          99.428949   \n",
       "4           400.008448   4998.532250     515.951814         389.885516   \n",
       "..                 ...           ...            ...                ...   \n",
       "793         228.849384   1881.758679     270.131464         229.574559   \n",
       "794          67.779332    534.546580      69.126916          62.007403   \n",
       "795          55.490387    444.462927      56.328566          51.557700   \n",
       "796         811.819607   7626.540682     963.369243         831.292934   \n",
       "797         562.100881   6966.990018     786.682558         759.401912   \n",
       "\n",
       "        Jobs.2003  Openings.2003  ...  Replacements.2030      Jobs.2031  \\\n",
       "0     9046.858183     838.099657  ...        1893.000897   29336.228198   \n",
       "1    47265.726935    5021.502312  ...       12054.862846  154152.343390   \n",
       "2      250.547165      20.575083  ...          30.056246     424.330956   \n",
       "3     1191.273163     109.273548  ...         153.029482    1777.853832   \n",
       "4     5029.295890     495.019726  ...        1534.479268   20006.057576   \n",
       "..            ...            ...  ...                ...            ...   \n",
       "793   1844.072183     280.490312  ...         617.149569    5124.679643   \n",
       "794    497.238806      77.010336  ...          11.550907     101.186765   \n",
       "795    408.282583      54.992191  ...          88.291228     783.633158   \n",
       "796   7758.161432     890.263296  ...        1071.491864    9938.374974   \n",
       "797   5061.183845    1156.905390  ...        3886.322868   36241.442371   \n",
       "\n",
       "     Openings.2031  Replacements.2031      Jobs.2032  Openings.2032  \\\n",
       "0      2544.536055        1936.191061   29944.563259    2540.088389   \n",
       "1     13581.069350       12178.035128  155555.327419   13522.607729   \n",
       "2        37.153531          30.551829     430.927037      37.367727   \n",
       "3       172.302763         154.673283    1795.368940     172.293758   \n",
       "4      1866.319212        1560.472491   20311.904296    1865.146091   \n",
       "..             ...                ...            ...            ...   \n",
       "793     683.938967         625.210916    5181.722582     681.522643   \n",
       "794      14.122842          11.737665     103.571943      13.251697   \n",
       "795     112.199974          90.901446     804.931685     114.514874   \n",
       "796    1190.661953        1083.282872   10045.754055    1201.641758   \n",
       "797    4478.711024        3950.317218   36769.836176    4483.520834   \n",
       "\n",
       "     Replacements.2032      Jobs.2033  Openings.2033  Replacements.2033  \n",
       "0          1976.341175   30508.302598    2539.545775        2013.547971  \n",
       "1         12288.870866  156788.715094   13479.537930       12386.308492  \n",
       "2            31.026747     437.263244      37.581246          31.482954  \n",
       "3           156.197098    1811.367608     171.647811         157.588982  \n",
       "4          1584.328535   20592.721852    1863.508498        1606.232304  \n",
       "..                 ...            ...            ...                ...  \n",
       "793         632.170155    5228.963573     680.855623         637.933556  \n",
       "794          12.014345     104.804102      13.011831          12.157276  \n",
       "795          93.372075     826.074484     114.891973          95.824640  \n",
       "796        1094.987192   10152.408621    1212.607178        1106.612540  \n",
       "797        4007.912143   37245.444867    4487.857196        4059.753491  \n",
       "\n",
       "[798 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = lightcast.query_corelmi('emsi.us.occupation', query)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query_corelmi` function will actually hit the API, and format the data it returns as a pandas DataFrame. From here you can use all of the typical pandas fuctionality to do what you need to with the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
